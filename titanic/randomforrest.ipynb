{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "wdir = '/Users/dwhitehead/Documents/github/kaggle/titanic/'\n",
    "\n",
    "# For .read_csv, always use header=0 when you know row 0 is the header row\n",
    "df = pd.read_csv(wdir + 'train.csv', header=0)\n",
    "df_test = pd.read_csv(wdir + 'test.csv', header=0)\n",
    "# print 'train'\n",
    "# print df.sample(5)\n",
    "# print 'test'\n",
    "# print df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category_to_factor(df, category_col):\n",
    "    mapper = {}\n",
    "    for i, x in enumerate(df[category_col].unique()):\n",
    "        mapper.update({x: i})\n",
    "    df[category_col + '_int'] = df[category_col].map(mapper).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean data:\n",
    "def clean_data(df):\n",
    "    # gender to binary\n",
    "    df['Gender'] = df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    ### null handling ###\n",
    "    ## Age\n",
    "    if len(df[df.Age.isnull()]) > 0:\n",
    "        # grab median age per passenger class as an array\n",
    "        median_ages = np.zeros((len(df.Gender.unique()),len(df.Pclass.unique())))\n",
    "        for i in range(0, len(df.Gender.unique())):\n",
    "            for j in range(0, len(df.Pclass.unique())):\n",
    "                median_ages[i,j] = df[(df['Gender'] == i) & (df['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "        # assign null age values to medians by class\n",
    "        df['AgeFill'] = df['Age']\n",
    "        for i in range(0, len(df.Gender.unique())):\n",
    "            for j in range(0, len(df.Pclass.unique())):\n",
    "                df.loc[(df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j+1), 'AgeFill'] = median_ages[i,j]\n",
    "        # null age as binary\n",
    "        df['AgeIsNull'] = pd.isnull(df.Age).astype(int)\n",
    "        \n",
    "    ## Fare\n",
    "    if len(df[df.Fare.isnull()]) > 0:\n",
    "        median_fare = np.zeros(len(df.Fare.unique()))\n",
    "        for f in range(0,len(df.Fare.unique())):\n",
    "            median_fare[f] = df[df.Pclass == f+1 ]['Fare'].dropna().median()\n",
    "        for f in range(0,len(df.Fare.unique())):\n",
    "            df.loc[(df.Fare.isnull()) & (df.Pclass == f+1 ), 'Fare'] = median_fare[f]\n",
    "            \n",
    "    # feature engineering\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "    df['Age*Class'] = df.AgeFill * df.Pclass\n",
    "    df = category_to_factor(df, 'Embarked')\n",
    "    df = df.drop(df.dtypes[df.dtypes.map(lambda x: x=='object')].index.tolist(), axis=1)\n",
    "    df = df.drop(['Age'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reorder dependent variable:\n",
    "def reorder_depvar(df, depvar):\n",
    "    l = [depvar]\n",
    "    for x in df.columns:\n",
    "        if x != depvar:\n",
    "            l.append(x)\n",
    "    df = df.reindex_axis(l, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = clean_data(df)\n",
    "df = reorder_depvar(df, 'Survived')\n",
    "train_data = df.values\n",
    "df_test = clean_data(df_test)\n",
    "test_data = df_test.values\n",
    "PassengerIds = df_test.PassengerId.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print df.Gender.unique()\n",
    "# print df.describe()\n",
    "# print df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the random forest package\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "l = []\n",
    "for x in range(0,500):\n",
    "    # Create the random forest object which will include all the parameters\n",
    "    # for the fit\n",
    "    forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "    # Fit the training data to the Survived labels and create the decision trees\n",
    "    forest = forest.fit(train_data[0::,1::],train_data[0::,0])\n",
    "\n",
    "    # Take the same decision trees and run it on the test data\n",
    "    output = forest.predict(test_data)\n",
    "    l.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418 <type 'numpy.ndarray'> [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1\n",
      " 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 0 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0]\n",
      "418 <type 'numpy.ndarray'> [ 892  893  894  895  896  897  898  899  900  901  902  903  904  905  906\n",
      "  907  908  909  910  911  912  913  914  915  916  917  918  919  920  921\n",
      "  922  923  924  925  926  927  928  929  930  931  932  933  934  935  936\n",
      "  937  938  939  940  941  942  943  944  945  946  947  948  949  950  951\n",
      "  952  953  954  955  956  957  958  959  960  961  962  963  964  965  966\n",
      "  967  968  969  970  971  972  973  974  975  976  977  978  979  980  981\n",
      "  982  983  984  985  986  987  988  989  990  991  992  993  994  995  996\n",
      "  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011\n",
      " 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026\n",
      " 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041\n",
      " 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056\n",
      " 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071\n",
      " 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086\n",
      " 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101\n",
      " 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116\n",
      " 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131\n",
      " 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146\n",
      " 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161\n",
      " 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176\n",
      " 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191\n",
      " 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206\n",
      " 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221\n",
      " 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236\n",
      " 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251\n",
      " 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266\n",
      " 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281\n",
      " 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296\n",
      " 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309]\n",
      "Done.\n",
      "[ 892  893  894  895  896  897  898  899  900  901  902  903  904  905  906\n",
      "  907  908  909  910  911  912  913  914  915  916  917  918  919  920  921\n",
      "  922  923  924  925  926  927  928  929  930  931  932  933  934  935  936\n",
      "  937  938  939  940  941  942  943  944  945  946  947  948  949  950  951\n",
      "  952  953  954  955  956  957  958  959  960  961  962  963  964  965  966\n",
      "  967  968  969  970  971  972  973  974  975  976  977  978  979  980  981\n",
      "  982  983  984  985  986  987  988  989  990  991  992  993  994  995  996\n",
      "  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011\n",
      " 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026\n",
      " 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041\n",
      " 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056\n",
      " 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071\n",
      " 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086\n",
      " 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101\n",
      " 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116\n",
      " 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131\n",
      " 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146\n",
      " 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161\n",
      " 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176\n",
      " 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191\n",
      " 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206\n",
      " 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221\n",
      " 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236\n",
      " 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251\n",
      " 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266\n",
      " 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281\n",
      " 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296\n",
      " 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    1    0    1    1    0\n",
      "    0    0    0    1    1    1    1    1    0    1    0    1    0    0    0\n",
      "    0    0    1    0    0    0    0    0    0    1    0    1    1    0    1\n",
      "    0    1    0    1    0    1    1    0    0    0    0    0    1    0    0\n",
      "    0    1    1    1    0    0    0    1    0    0    0    1    1    1    0\n",
      "    1    0    0    1    0    1    0    0    0    0    0    0    1    0    0\n",
      "    1    0    1    0    1    0    0    0    1    0    0    0    1    0    0\n",
      "    0    0    0    0    0    1    1    1    0    0    1    0    1    1    0\n",
      "    1    0    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
      "    0    0    0    0    1    0    0    1    0    0    0    1    0    1    0\n",
      "    0    0    0    0    1    0    1    1    0    1    1    0    0    0    1\n",
      "    0    1    0    0    0    0    0    0    1    1    1    1    1    0    0\n",
      "    1    0    1    0    1    0    0    0    0    0    1    0    1    0    1\n",
      "    0    0    0    0    1    0    1    0    0    0    0    1    0    0    0\n",
      "    0    0    0    0    0    0    1    0    1    0    1    0    1    0    0\n",
      "    0    0    0    0    1    0    0    0    0    0    0    1    1    1    1\n",
      "    0    0    0    1    1    0    1    0    1    0    1    0    0    0    0\n",
      "    0    1    0    0    0    1    1    0    0    0    0    0    0    0    0\n",
      "    1    1    0    1    0    0    0    0    0    1    0    0    1    0    0\n",
      "    1    0    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
      "    0    0    0    1    1    1    0    0    0    0    0    0    1    0    0\n",
      "    0    0    0    0    0    0    1    1    0    1    0    0    0    1    1\n",
      "    0    0    0    0    0    0    0    0    0    0    0    1    1    1    0\n",
      "    0    0    1    1    0    0    0    1    1    1    0    0    0    0    1\n",
      "    1    0    1    0    0    0    1    0    0    1    0    0    1    1    0\n",
      "    0    1    0    0    0    0    1    0    1    0    0    0    0    1    1\n",
      "    0    0    0    1    0    1    0    0    1    0    1    1    1    0    0\n",
      "    0    0    1    0    1    0    0    1    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "sum_output = np.zeros_like(l[0])\n",
    "\n",
    "for output in l:\n",
    "    sum_output += output\n",
    "\n",
    "avg_output = []\n",
    "final_output = []\n",
    "for x in sum_output:\n",
    "    avg_output.append(x/500)\n",
    "    if x/500 < .5:\n",
    "        final_output.append(0)\n",
    "    else:\n",
    "        final_output.append(1)\n",
    "        \n",
    "        \n",
    "# print avg_output\n",
    "final_output = np.array(final_output)\n",
    "print len(final_output), type(final_output), final_output\n",
    "# print test_data[0,0::]\n",
    "print len(PassengerIds), type(PassengerIds), PassengerIds\n",
    "\n",
    "import csv\n",
    "predictions_file = open(\"randomforrest.csv\", \"wb\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n",
    "open_file_object.writerows(zip(PassengerIds, final_output))\n",
    "predictions_file.close()\n",
    "print 'Done.'\n",
    "\n",
    "\n",
    "final_array = np.concatenate((PassengerIds, final_output), axis=0)\n",
    "\n",
    "print final_array\n",
    "\n",
    "# print l[0]==l[1]\n",
    "# print l[0]\n",
    "# print l[1]\n",
    "# print l[0] + l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
